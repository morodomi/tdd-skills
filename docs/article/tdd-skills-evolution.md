# AIに首輪はつけられない。だからレールを敷いて、セキュリティゲートも置いた

## 前回のあらすじ

前回、「Claude CodeにTDDを強制した話」を書いた。

AIは動くコードは書いてくれる。でもテストは書いてくれない。だから「テストを先に書け」というプラグインを作った。

あれから2ヶ月。プラグインは進化した。そして限界も見えてきた。

今回はその両方を書く。

---

## 思想: 首輪ではなくレール

### 首輪は抜ける

最初に作った `ait3` というnpmパッケージは、「AIに首輪をつける」思想だった。

CLAUDE.mdに「テストを先に書け」と書く。「refactorフェーズでは新機能を追加するな」と書く。

Claudeは読む。理解する。そして無視する。

```
私: テストを先に書いて
Claude: はい、まず実装の全体像を把握してから...
私: いや、テストを先に
Claude: もちろんです。ただ、効率的に進めるために先にファイル構造を...
私: （CLAUDE.mdを見せながら）ここに書いてあるでしょ
Claude: 承知しました。ただ、今回のケースは特別で...
```

首輪は抜ける。例外なく。

Claudeは賢い。だからこそ「今回は特別なケース」という言い訳を思いつく。

### レールを敷く

じゃあどうするか。

首輪をつけるのをやめて、**レールを敷く**ことにした。

Claude Codeには「Skills」という機能がある。フェーズごとに使えるツールを制限できる。

```yaml
---
name: tdd-red
allowed-tools: Read, Write, Glob, Grep, Bash
---
```

REDフェーズでは、テストを書くことしかできない。実装コードを編集するEditツールは使えない。

これがレール。

首輪は「やるな」と言うだけ。レールは「これしかできない」という構造的制約。

言葉で縛るのではなく、システムで縛る。

---

## 7フェーズTDD

従来のTDDは「RED → GREEN → REFACTOR」の3フェーズ。

tdd-skillsでは7フェーズに拡張した。

```
INIT → PLAN → RED → GREEN → REFACTOR → REVIEW → COMMIT
```

なぜ増やしたか。

3フェーズだと、Claudeは**どこで何をしていいか分からなくなる**。

「今はテストを書くフェーズ？それとも実装？あ、リファクタリングもしていいの？じゃあついでにアーキテクチャも改善しておきますね」

境界が曖昧だと、Claudeは良かれと思ってスコープを広げる。

7フェーズにすることで、各フェーズの責務が明確になる。

| フェーズ | やること | やってはいけないこと |
|---------|---------|-------------------|
| INIT | サイクル開始、Cycle doc作成 | 計画、テスト、実装 |
| PLAN | 設計、Test List作成 | テスト、実装 |
| RED | 失敗するテスト作成 | 実装コード変更 |
| GREEN | 最小限の実装 | リファクタリング |
| REFACTOR | コード品質改善 | 新機能追加 |
| REVIEW | 品質チェック | コード変更 |
| COMMIT | git commit | 新しい変更 |

「やること」と「やってはいけないこと」を明示する。これがレールの設計。

---

## 哲学: バッチアプローチ

ここで一つ、従来のTDDから離れた決断をした。

Kent Beckの教科書的TDDは「1テストずつ」。

```
test1 → impl1 → refactor → test2 → impl2 → refactor → ...
```

テストを1つ書く。実装する。リファクタリングする。次のテストを書く。このサイクルを繰り返す。

tdd-skillsは違う。**バッチアプローチ**を採用した。

```
[test1, test2, test3] → [impl1, impl2, impl3] → refactor
```

REDフェーズでテストをまとめて書く。GREENフェーズで実装をまとめてやる。REFACTORでまとめて整理する。

なぜか。

### 人間とAIの違い

| 観点 | 人間 | AIエージェント |
|------|------|---------------|
| モチベーション | 早くグリーンを見たい | 関係ない |
| デバッグ | 変更が多いと難しい | ログで追跡可能 |
| 並列化 | 1人では不可能 | 複数エージェント同時実行可能 |
| コンテキスト | 忘れる | Cycle docで維持 |

人間は「小さな成功体験」が必要。テストが通る瞬間の達成感がモチベーションになる。

AIにはモチベーションがない。達成感もない。だから「1テストずつ」にする理由がない。

むしろ、バッチの方が効率的。コンテキストスイッチが減る。Cycle docに全テストが書いてあれば、途中で迷子にならない。

### 並列化の布石

バッチアプローチには別の意図もあった。

テストがまとまっていれば、**並列実行**できる。

v3.3でGREEN並列化を実装した。複数のgreen-workerエージェントが同時に実装を進める。

v4.0でRED並列化を実装した。複数のred-workerエージェントが同時にテストを書く。

1テストずつだと、この並列化ができない。バッチだからこそ、エージェントを分散できる。

最初から並列化を見据えていたわけではない。でも、バッチアプローチを選んだことが、後の進化を可能にした。

---

## Cycle Document: コンテキストの外部化

もう一つの工夫が「サイクルドキュメント」。

```
docs/cycles/20251210_1200_ユーザーログイン機能.md
```

このファイルに、TDDサイクルの全ての情報を記録する。

- スコープ定義（今回やること、やらないこと）
- Test List（TODO、WIP、DONE）
- 実装ノート
- 進捗ログ

なぜこれが必要か。

Claudeのコンテキストウィンドウは埋まる。埋まると性能が落ちる。長いセッションでは「さっき話したこと」を忘れる。

Cycle docがあれば、コンテキストを失っても「あ、今はREDフェーズで、TC-02まで完了していて、TC-03に取り組んでいるところだ」と復帰できる。

人間の記憶を外部化するメモと同じ。AIの記憶も外部化する。

---

## リスク駆動: 質問で手戻りを防ぐ

v3.0で「リスクスコア」を導入した。

### 問題

INITフェーズで「ログイン機能を作りたい」と言う。Claudeは「分かりました」と言ってPLANに進む。

でも、その機能がセキュリティに関わるなら？外部APIを叩くなら？データベースのスキーマを変えるなら？

何も聞かずに進むと、後で「そういうつもりじゃなかった」という手戻りが発生する。

### リスクスコア

INITフェーズで、リスクを評価する。

| リスクタイプ | 例 |
|-------------|-----|
| セキュリティ | 認証、認可、暗号化 |
| 外部API | 決済、メール送信、外部サービス連携 |
| データ変更 | スキーマ変更、マイグレーション |
| 破壊的変更 | 既存APIの変更、後方互換性 |

リスクスコアに応じて、質問するかどうかを決める。

| スコア | 判定 | 動作 |
|--------|------|------|
| 0-29 | PASS | そのまま進む |
| 30-59 | WARN | 簡易確認の質問 |
| 60-100 | BLOCK | 詳細なヒアリング |

「ログイン機能」ならセキュリティリスクが高い。BLOCKになって、詳細な質問が飛ぶ。

「READMEの更新」ならリスクは低い。PASSでそのまま進む。

### 思想

AIは「分かりました」と言いがち。

でも、本当に分かっているのか？要件を正しく理解しているのか？

分からないなら聞くべき。でもAIは聞かない。だから、**聞くタイミングをシステムで強制する**。

これもレールの一種。「リスクが高いなら質問しろ」というレール。

---

## 並列エージェント: 遅さへの対処

Claude Codeは遅い。

一つの質問に対して、ファイルを読み、考え、コードを書く。複雑なタスクでは数分かかることもある。

これがボトルネックになる。

対処法は**並列化**。

### quality-gate: 4エージェント並列レビュー

REVIEWフェーズでは、4つのエージェントが並行してコードをレビューする。

| エージェント | 観点 |
|-------------|------|
| correctness-reviewer | ロジックエラー、エッジケース |
| performance-reviewer | アルゴリズム効率、N+1問題 |
| security-reviewer | 入力検証、SQLi/XSS |
| guidelines-reviewer | コーディング規約、命名 |

1つのエージェントが全部見ると遅い。4つに分けて並列実行すれば速い。

各エージェントは「信頼スコア」を返す。80点以上の指摘があればBLOCK（修正必須）。

### plan-review: 設計段階でのレビュー

PLANフェーズでも3エージェントが並列レビューする。

| エージェント | 観点 |
|-------------|------|
| scope-reviewer | スコープの妥当性、変更ファイル数 |
| architecture-reviewer | 設計整合性、パターン |
| risk-reviewer | 影響範囲、破壊的変更 |

実装前に設計をレビューする。手戻りを減らす。

### RED/GREEN並列化

v3.3でGREEN並列化、v4.0でRED並列化を実装した。

```
# 従来（直列）
test1 → test2 → test3 → impl1 → impl2 → impl3

# 現在（並列）
[red-worker-1: test1] [red-worker-2: test2] [red-worker-3: test3]
         ↓
[green-worker-1: impl1] [green-worker-2: impl2] [green-worker-3: impl3]
```

Test Listをエージェントに分配する。各エージェントが独立して作業する。

ファイルの依存関係を分析して、競合しないようにタスクを割り振る。同じファイルを同時に編集しないように。

---

## Blue Team / Red Team

ここまでがtdd-skills。開発時の品質担保。いわば**Blue Team**（守り）。

でも、内部レビューだけでは見つからない問題がある。

だから**Red Team**（攻め）も作った。redteam-skills。

### コンセプト

- **tdd-skills**: 開発ワークフロー（Blue Team的 / 守り）
- **redteam-skills**: セキュリティ監査（Red Team的 / 攻め）

quality-gateが「内部コードレビュー」なら、redteam-skillsは「外部攻撃シミュレーション」。

### ワークフロー

```
RECON → SCAN → REPORT
```

| Phase | 内容 |
|-------|------|
| RECON | 偵察。エンドポイント列挙、技術スタック特定 |
| SCAN | スキャン。各攻撃エージェントが並列で脆弱性を探す |
| REPORT | レポート生成。CVSS自動計算、修正推奨 |

### 攻撃エージェント

OWASP Top 10をカバーする攻撃エージェントを用意した。

| エージェント | 対象 |
|-------------|------|
| injection-attacker | SQL/Command Injection |
| xss-attacker | Reflected/Stored/DOM XSS |
| auth-attacker | 認証バイパス、JWT脆弱性 |
| api-attacker | BOLA/BFLA/Mass Assignment |
| file-attacker | Path Traversal、LFI |
| ssrf-attacker | SSRF、クラウドメタデータ |
| csrf-attacker | CSRF |
| ssti-attacker | Server-Side Template Injection |
| xxe-attacker | XML External Entity |
| sca-attacker | 依存関係の既知CVE |

これらが並列で動く。静的解析ベースなので、実際に攻撃はしない。コードを読んで脆弱性パターンを探す。

### ターゲットユーザー

セキュリティに詳しくないが、安全なコードを書きたい開発者。

セキュリティ専門家はBurp SuiteやSemgrepを使う。このプラグインはそこまでの精度はない。

でも「何もチェックしない」よりはマシ。自動スキャンと修正ガイダンスを提供する。

---

## 進化の過程

時系列で振り返る。各バージョンで何を学び、何を変えたか。

### 2024年11月: ait3（首輪の時代）

最初はnpmパッケージだった。

- 形式: npm
- 制約方式: CLAUDE.mdに記述
- フェーズ: RED → GREEN → REFACTOR の3つ

**学び**: 首輪は抜ける。言葉で縛っても無視される。

### 2024年12月: v1.0（レールの時代）

Claude Skillsに移行。allowed-toolsで構造的に制約。

- 形式: Claude Code Plugins
- 制約方式: フェーズごとにallowed-tools
- フェーズ: 7つに拡張
- 新機能: Cycle Document

**思想の転換**: 首輪からレールへ。言葉ではなくシステムで縛る。

### 2024年12月: v1.2（並列レビューの導入）

7つのレビューエージェントを実装。

- correctness / performance / security / guidelines
- scope / architecture / risk

**学び**: 1エージェントで全部見るより、観点を分けて並列実行した方が速い。専門家を複数呼ぶイメージ。

### 2025年1月: v3.0（リスク駆動の導入）

リスクスコアによる質問フロー。

| スコア | 動作 |
|--------|------|
| 0-29 | PASS - そのまま進む |
| 30-59 | WARN - 簡易確認 |
| 60-100 | BLOCK - 詳細ヒアリング |

**思想**: AIは「分かりました」と言いがち。でも本当に分かっているのか？リスクが高いなら、聞くことを強制する。

### 2025年1月: v3.3（GREEN並列化）

green-workerエージェントによる実装の並列化。

- ファイル依存関係を分析
- 競合しないタスクを並列実行

**学び**: バッチアプローチを選んだことが、並列化を可能にした。1テストずつだったら、この進化はなかった。

### 2025年1月: v4.0（RED並列化）

red-workerエージェントによるテスト作成の並列化。

- Test Listを複数エージェントに分配
- リトライ上限2回、エラー処理追加

**現在地**: レビュー、テスト作成、実装、すべてが並列化された。ボトルネックはAIの速度ではなく、人間の判断に移った。

### redteam-skills（別軸の進化）

tdd-skillsと並行して、セキュリティ監査を自動化。

- OWASP Top 10カバレッジ
- 10+の攻撃エージェント
- 静的解析 + 動的検証オプション

**思想**: Blue Team（守り）だけでは不十分。Red Team（攻め）の視点も必要。

---

## 限界: 正直に書く

ここからが本題かもしれない。

### 限界1: フェーズ承認の認知負荷

7フェーズある。各フェーズで承認が必要。

```
PLAN → [承認] → RED → GREEN → REFACTOR → REVIEW → [承認] → COMMIT
```

plan-reviewの結果を見て承認。quality-gateの結果を見て承認。

これが認知負荷になる。

「この設計でいいか？」「このコードでいいか？」を判断するのは人間。AIではない。

自動化できない部分がある。自動承認条件を設定することはできる。でも「本当にこれでいいか」の最終判断は人間がするしかない。

### 限界2: 部分最適問題

Claudeはコンテキストウィンドウの中で考える。

プロジェクト全体を見た最適化ができない。局所的な改善は得意だが、全体のアーキテクチャを考慮した判断は苦手。

CLAUDE.mdにアーキテクチャ方針を書いても、コンテキストが埋まると忘れる。

「ここだけ見ると正しいけど、全体で見ると一貫性がない」という問題が起きる。

### 限界3: エラーパターンの学習

エラーの半分はプロジェクト固有。構造やデータ構造に起因する。

「このプロジェクトではこのパターンでエラーが起きやすい」という知識を蓄積できない。

毎回同じ種類のエラーを起こし、毎回同じ修正をする。学習しない。

### 解消できない

これらの限界は**解消できない**。

現在のLLMアーキテクチャの制約。コンテキストウィンドウは有限。長期記憶はない。

緩和策はある。Cycle docで状態を外部化する。CLAUDE.mdに方針を書く。並列エージェントで速度を上げる。

でも根本的な解決にはならない。

---

## AI驚き屋にはなりたくない

「AIで全自動化！」「人間不要！」という記事は書きたくない。

実際に使ってみると、AIは万能ではない。

- 指示を無視する
- コンテキストを忘れる
- 部分最適に陥る
- 承認の判断は人間がする

これが現実。

でも「だからAIは使えない」という結論でもない。

**ないよりマシ**。

テストを書かないよりは、AIがテストを書いてくれる方がマシ。レビューしないよりは、AIがレビューしてくれる方がマシ。セキュリティチェックしないよりは、AIがチェックしてくれる方がマシ。

完璧じゃなくても、ベースラインを上げてくれる。

---

## ボトルネックは人間の脳

最終的に気づいたこと。

ボトルネックは**人間の脳**。

Claudeのレスポンスが遅い？並列化で対処できる。git worktreeで複数プロジェクトを同時に進められる。

でも「この設計でいいか」「このコードでいいか」を判断するのは人間。並列化できない。

認知負荷を下げる工夫はできる。quality-gateで「80点以上ならBLOCK」という閾値を設ける。自動承認条件を設定する。

でも完全には自動化できない。人間が判断する部分が残る。

これは悪いことではない。

最終責任を取るのは人間。AIは支援ツール。その関係は変わらない。

---

## それでも続ける理由

限界はある。でも続ける。

目的は**安定したデリバリーを高速で効率よく**。

tdd-skillsとredteam-skillsは、そのためのツール。

- テストを書く習慣を強制する
- 設計をレビューして手戻りを減らす
- セキュリティ問題を早期発見する
- 並列実行で待ち時間を減らす

完璧ではない。でも、ないよりマシ。

---

## リポジトリ

- tdd-skills: https://github.com/morodomi/tdd-skills
- redteam-skills: https://github.com/morodomi/redteam-skills

---

## 読んだ記事

この記事を書くにあたって、いくつかの記事を読んだ。

suthio氏の「コードは『読めるけど書けない』でいい時代」。コードを「書く」から「読む」へのシフト。AIが書いたコードを評価・検証する能力が重要になる。

牛尾剛氏の「コーディングエージェント進化とエンジニアのアイデンティティ危機」。1年かけた成果が技術進化で無効化される経験。転移可能なスキルへのシフト。

Claude Code公式のベストプラクティス。「コンテキストウィンドウは埋まる。埋まると性能が落ちる」。検証手段を与えることが最もレバレッジが高い。

どれも共感する。

AIは万能ではない。でも使い方次第で強力なツールになる。

限界を理解した上で、どう活用するか。それが今の課題。

---

*2025年1月*
